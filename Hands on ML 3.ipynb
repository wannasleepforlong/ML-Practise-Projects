{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMDexd38MmcBlOtOm1BjCzh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"BQCw8VQIiUF3","executionInfo":{"status":"ok","timestamp":1684253157437,"user_tz":-330,"elapsed":8526,"user":{"displayName":"Abhinav Painuli","userId":"09195255305626144528"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow import keras\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense,Flatten"]},{"cell_type":"code","source":["fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n","(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lwQmSv9xjn34","executionInfo":{"status":"ok","timestamp":1684253159532,"user_tz":-330,"elapsed":2135,"user":{"displayName":"Abhinav Painuli","userId":"09195255305626144528"}},"outputId":"358ae0e2-9be2-402d-9ad7-714aa65090a2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","29515/29515 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26421880/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","5148/5148 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4422102/4422102 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n","X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]#validation set"],"metadata":{"id":"RXLKiG1Blzxe","executionInfo":{"status":"ok","timestamp":1684253159533,"user_tz":-330,"elapsed":24,"user":{"displayName":"Abhinav Painuli","userId":"09195255305626144528"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vyWdcFeMl9rz","executionInfo":{"status":"ok","timestamp":1684253159535,"user_tz":-330,"elapsed":23,"user":{"displayName":"Abhinav Painuli","userId":"09195255305626144528"}},"outputId":"6d352e85-468a-428e-c53c-fc0645e7b102"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(55000, 28, 28)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["X_train.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sHGpjwtAmfdj","executionInfo":{"status":"ok","timestamp":1684253160348,"user_tz":-330,"elapsed":830,"user":{"displayName":"Abhinav Painuli","userId":"09195255305626144528"}},"outputId":"a43678a6-4a96-4ad2-f884-1b21ea40ca54"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dtype('uint8')"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["X_train[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SATlRf9MneNt","executionInfo":{"status":"ok","timestamp":1684253160350,"user_tz":-330,"elapsed":51,"user":{"displayName":"Abhinav Painuli","userId":"09195255305626144528"}},"outputId":"76bf1c87-8083-449b-c418-aebbc9313fa9"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n","          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n","          1,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n","          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n","          0,   3],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n","          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n","         10,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n","         72,  15],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n","         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n","        172,  66],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n","        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n","        229,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n","        173,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n","        202,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n","        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n","        209,  52],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n","        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n","        167,  56],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n","        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n","         92,   0],\n","       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n","        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n","         77,   0],\n","       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n","        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n","        159,   0],\n","       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n","        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n","        215,   0],\n","       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n","        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n","        246,   0],\n","       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n","         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n","        225,   0],\n","       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n","        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n","        229,  29],\n","       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n","        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n","        230,  67],\n","       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n","        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n","        206, 115],\n","       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n","        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n","        210,  92],\n","       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n","        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n","        170,   0],\n","       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n","        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=uint8)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255.\n"],"metadata":{"id":"1VKlqjjOmqvh","executionInfo":{"status":"ok","timestamp":1684253160352,"user_tz":-330,"elapsed":49,"user":{"displayName":"Abhinav Painuli","userId":"09195255305626144528"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["print(X_train[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VOvd6VFVnSR4","executionInfo":{"status":"ok","timestamp":1684253160355,"user_tz":-330,"elapsed":50,"user":{"displayName":"Abhinav Painuli","userId":"09195255305626144528"}},"outputId":"3d700e5b-bed7-4557-aef9-88497bfc0eda"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.00392157 0.         0.         0.05098039 0.28627451 0.\n","  0.         0.00392157 0.01568627 0.         0.         0.\n","  0.         0.00392157 0.00392157 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.01176471 0.         0.14117647 0.53333333 0.49803922 0.24313725\n","  0.21176471 0.         0.         0.         0.00392157 0.01176471\n","  0.01568627 0.         0.         0.01176471]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.02352941 0.         0.4        0.8        0.69019608 0.5254902\n","  0.56470588 0.48235294 0.09019608 0.         0.         0.\n","  0.         0.04705882 0.03921569 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.60784314 0.9254902  0.81176471 0.69803922\n","  0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608\n","  0.30196078 0.50980392 0.28235294 0.05882353]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.00392157\n","  0.         0.27058824 0.81176471 0.8745098  0.85490196 0.84705882\n","  0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902\n","  0.55294118 0.34509804 0.6745098  0.25882353]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.00392157 0.00392157 0.00392157\n","  0.         0.78431373 0.90980392 0.90980392 0.91372549 0.89803922\n","  0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922\n","  0.48235294 0.76862745 0.89803922 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765\n","  0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667\n","  0.8745098  0.96078431 0.67843137 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.75686275 0.89411765 0.85490196 0.83529412 0.77647059\n","  0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098\n","  0.8627451  0.95294118 0.79215686 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.00392157 0.01176471 0.\n","  0.04705882 0.85882353 0.8627451  0.83137255 0.85490196 0.75294118\n","  0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255\n","  0.88627451 0.77254902 0.81960784 0.20392157]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.02352941 0.\n","  0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843\n","  0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451\n","  0.96078431 0.46666667 0.65490196 0.21960784]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.01568627 0.         0.\n","  0.21568627 0.9254902  0.89411765 0.90196078 0.89411765 0.94117647\n","  0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039\n","  0.85098039 0.81960784 0.36078431 0.        ]\n"," [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098\n","  0.00784314 0.         0.         0.         0.         0.\n","  0.92941176 0.88627451 0.85098039 0.8745098  0.87058824 0.85882353\n","  0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725\n","  0.85490196 1.         0.30196078 0.        ]\n"," [0.         0.01176471 0.         0.         0.         0.\n","  0.         0.         0.         0.24313725 0.56862745 0.8\n","  0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627\n","  0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725\n","  0.87843137 0.95686275 0.62352941 0.        ]\n"," [0.         0.         0.         0.         0.07058824 0.17254902\n","  0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824\n","  0.85098039 0.88627451 0.78431373 0.80392157 0.82745098 0.90196078\n","  0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902\n","  0.91372549 0.93333333 0.84313725 0.        ]\n"," [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667\n","  0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784\n","  0.78431373 0.62352941 0.96078431 0.75686275 0.80784314 0.8745098\n","  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098\n","  0.8627451  0.90980392 0.96470588 0.        ]\n"," [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098\n","  0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451\n","  0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667\n","  0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784\n","  0.87058824 0.89411765 0.88235294 0.        ]\n"," [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922\n","  0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725\n","  0.85098039 0.94509804 0.25490196 0.28627451 0.41568627 0.45882353\n","  0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098\n","  0.8745098  0.87843137 0.89803922 0.11372549]\n"," [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157\n","  0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314\n","  0.77647059 0.83529412 0.94117647 0.76470588 0.89019608 0.96078431\n","  0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824\n","  0.8627451  0.86666667 0.90196078 0.2627451 ]\n"," [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902\n","  0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569\n","  0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882\n","  0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098\n","  0.70980392 0.80392157 0.80784314 0.45098039]\n"," [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824\n","  0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471\n","  0.82745098 0.82352941 0.78431373 0.76862745 0.76078431 0.74901961\n","  0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471\n","  0.65490196 0.69411765 0.82352941 0.36078431]\n"," [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961\n","  0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549\n","  0.74117647 0.7372549  0.75686275 0.77647059 0.8        0.81960784\n","  0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431\n","  0.75294118 0.84705882 0.66666667 0.        ]\n"," [0.00784314 0.         0.         0.         0.25882353 0.78431373\n","  0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118\n","  0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078\n","  0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353\n","  0.38823529 0.22745098 0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431\n","  0.1372549  0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]]\n"]}]},{"cell_type":"code","source":["unique_values = list(set(y_train_full))\n","unique_values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_eCS4uIGqQu9","executionInfo":{"status":"ok","timestamp":1684253160828,"user_tz":-330,"elapsed":507,"user":{"displayName":"Abhinav Painuli","userId":"09195255305626144528"}},"outputId":"be942bfd-0b38-494e-cabd-f3216b84ca1d"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["\n","tf.random.set_seed(3)#so that random in sequential stays same\n","model=Sequential()\n","model.add(Dense(300,activation=\"relu\",input_shape=(28,28)))\n","model.add(Flatten())\n","model.add(Dense(100,activation=\"relu\"))\n","model.add(Dense(10,activation='softmax'))"],"metadata":{"id":"aIbMRCjlnZxQ","executionInfo":{"status":"ok","timestamp":1684253161463,"user_tz":-330,"elapsed":645,"user":{"displayName":"Abhinav Painuli","userId":"09195255305626144528"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"8fOYvU7xsDiz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684253181376,"user_tz":-330,"elapsed":22,"user":{"displayName":"Abhinav Painuli","userId":"09195255305626144528"}},"outputId":"d0404b9b-5c75-4d78-f39e-55829a501eb0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 28, 300)           8700      \n","                                                                 \n"," flatten (Flatten)           (None, 8400)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 100)               840100    \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 849,810\n","Trainable params: 849,810\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"],"metadata":{"id":"ibAXAuSXUAAj","executionInfo":{"status":"ok","timestamp":1684254097727,"user_tz":-330,"elapsed":614,"user":{"displayName":"Abhinav Painuli","userId":"09195255305626144528"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["history=model.fit(X_train,y_train,epochs=50,validation_data=(X_valid,y_valid))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ExC4rCzeW50Y","executionInfo":{"status":"ok","timestamp":1684255486621,"user_tz":-330,"elapsed":1344725,"user":{"displayName":"Abhinav Painuli","userId":"09195255305626144528"}},"outputId":"578e20f8-d5cd-4c1f-9cdd-018e32fe526b"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","1719/1719 [==============================] - 29s 16ms/step - loss: 0.7102 - accuracy: 0.7649 - val_loss: 0.5174 - val_accuracy: 0.8232\n","Epoch 2/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.4842 - accuracy: 0.8304 - val_loss: 0.4511 - val_accuracy: 0.8396\n","Epoch 3/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.4397 - accuracy: 0.8469 - val_loss: 0.4349 - val_accuracy: 0.8452\n","Epoch 4/50\n","1719/1719 [==============================] - 28s 16ms/step - loss: 0.4113 - accuracy: 0.8572 - val_loss: 0.3956 - val_accuracy: 0.8570\n","Epoch 5/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.3911 - accuracy: 0.8634 - val_loss: 0.3812 - val_accuracy: 0.8628\n","Epoch 6/50\n","1719/1719 [==============================] - 25s 15ms/step - loss: 0.3745 - accuracy: 0.8689 - val_loss: 0.3696 - val_accuracy: 0.8672\n","Epoch 7/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.3610 - accuracy: 0.8745 - val_loss: 0.3640 - val_accuracy: 0.8680\n","Epoch 8/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.3497 - accuracy: 0.8771 - val_loss: 0.3580 - val_accuracy: 0.8688\n","Epoch 9/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.3396 - accuracy: 0.8806 - val_loss: 0.3555 - val_accuracy: 0.8714\n","Epoch 10/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.3303 - accuracy: 0.8837 - val_loss: 0.3627 - val_accuracy: 0.8690\n","Epoch 11/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.3215 - accuracy: 0.8863 - val_loss: 0.3335 - val_accuracy: 0.8780\n","Epoch 12/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.3143 - accuracy: 0.8882 - val_loss: 0.3294 - val_accuracy: 0.8778\n","Epoch 13/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.3062 - accuracy: 0.8913 - val_loss: 0.3275 - val_accuracy: 0.8796\n","Epoch 14/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.2998 - accuracy: 0.8936 - val_loss: 0.3280 - val_accuracy: 0.8808\n","Epoch 15/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.2931 - accuracy: 0.8950 - val_loss: 0.3180 - val_accuracy: 0.8802\n","Epoch 16/50\n","1719/1719 [==============================] - 25s 15ms/step - loss: 0.2866 - accuracy: 0.8979 - val_loss: 0.3132 - val_accuracy: 0.8852\n","Epoch 17/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.2819 - accuracy: 0.8997 - val_loss: 0.3124 - val_accuracy: 0.8848\n","Epoch 18/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.2757 - accuracy: 0.9015 - val_loss: 0.3111 - val_accuracy: 0.8832\n","Epoch 19/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.2708 - accuracy: 0.9043 - val_loss: 0.3066 - val_accuracy: 0.8860\n","Epoch 20/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.2654 - accuracy: 0.9047 - val_loss: 0.3139 - val_accuracy: 0.8836\n","Epoch 21/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.2610 - accuracy: 0.9071 - val_loss: 0.3351 - val_accuracy: 0.8758\n","Epoch 22/50\n","1719/1719 [==============================] - 25s 15ms/step - loss: 0.2566 - accuracy: 0.9086 - val_loss: 0.3213 - val_accuracy: 0.8770\n","Epoch 23/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.2525 - accuracy: 0.9090 - val_loss: 0.3005 - val_accuracy: 0.8904\n","Epoch 24/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.2472 - accuracy: 0.9113 - val_loss: 0.2961 - val_accuracy: 0.8906\n","Epoch 25/50\n","1719/1719 [==============================] - 25s 15ms/step - loss: 0.2430 - accuracy: 0.9132 - val_loss: 0.2932 - val_accuracy: 0.8926\n","Epoch 26/50\n","1719/1719 [==============================] - 25s 15ms/step - loss: 0.2382 - accuracy: 0.9155 - val_loss: 0.2938 - val_accuracy: 0.8932\n","Epoch 27/50\n","1719/1719 [==============================] - 25s 15ms/step - loss: 0.2347 - accuracy: 0.9157 - val_loss: 0.2989 - val_accuracy: 0.8868\n","Epoch 28/50\n","1719/1719 [==============================] - 25s 15ms/step - loss: 0.2312 - accuracy: 0.9168 - val_loss: 0.3042 - val_accuracy: 0.8900\n","Epoch 29/50\n","1719/1719 [==============================] - 25s 14ms/step - loss: 0.2274 - accuracy: 0.9179 - val_loss: 0.2941 - val_accuracy: 0.8914\n","Epoch 30/50\n","1719/1719 [==============================] - 24s 14ms/step - loss: 0.2236 - accuracy: 0.9198 - val_loss: 0.2843 - val_accuracy: 0.8936\n","Epoch 31/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.2200 - accuracy: 0.9211 - val_loss: 0.2911 - val_accuracy: 0.8936\n","Epoch 32/50\n","1719/1719 [==============================] - 25s 15ms/step - loss: 0.2170 - accuracy: 0.9223 - val_loss: 0.2819 - val_accuracy: 0.8936\n","Epoch 33/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.2129 - accuracy: 0.9240 - val_loss: 0.2836 - val_accuracy: 0.8950\n","Epoch 34/50\n","1719/1719 [==============================] - 25s 15ms/step - loss: 0.2091 - accuracy: 0.9259 - val_loss: 0.2850 - val_accuracy: 0.8970\n","Epoch 35/50\n","1719/1719 [==============================] - 25s 15ms/step - loss: 0.2063 - accuracy: 0.9263 - val_loss: 0.2888 - val_accuracy: 0.8952\n","Epoch 36/50\n","1719/1719 [==============================] - 25s 15ms/step - loss: 0.2032 - accuracy: 0.9273 - val_loss: 0.2960 - val_accuracy: 0.8900\n","Epoch 37/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.1995 - accuracy: 0.9288 - val_loss: 0.2815 - val_accuracy: 0.8948\n","Epoch 38/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.1972 - accuracy: 0.9296 - val_loss: 0.2844 - val_accuracy: 0.8952\n","Epoch 39/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.1932 - accuracy: 0.9312 - val_loss: 0.2874 - val_accuracy: 0.8952\n","Epoch 40/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.1902 - accuracy: 0.9327 - val_loss: 0.2848 - val_accuracy: 0.8978\n","Epoch 41/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.1870 - accuracy: 0.9339 - val_loss: 0.3052 - val_accuracy: 0.8866\n","Epoch 42/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.1845 - accuracy: 0.9347 - val_loss: 0.2838 - val_accuracy: 0.8988\n","Epoch 43/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.1810 - accuracy: 0.9363 - val_loss: 0.2831 - val_accuracy: 0.8990\n","Epoch 44/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.1783 - accuracy: 0.9370 - val_loss: 0.2759 - val_accuracy: 0.8998\n","Epoch 45/50\n","1719/1719 [==============================] - 26s 15ms/step - loss: 0.1757 - accuracy: 0.9376 - val_loss: 0.2792 - val_accuracy: 0.8990\n","Epoch 46/50\n","1719/1719 [==============================] - 27s 16ms/step - loss: 0.1723 - accuracy: 0.9389 - val_loss: 0.2739 - val_accuracy: 0.9044\n","Epoch 47/50\n","1719/1719 [==============================] - 25s 15ms/step - loss: 0.1700 - accuracy: 0.9405 - val_loss: 0.2921 - val_accuracy: 0.8946\n","Epoch 48/50\n","1719/1719 [==============================] - 25s 15ms/step - loss: 0.1672 - accuracy: 0.9411 - val_loss: 0.2786 - val_accuracy: 0.9020\n","Epoch 49/50\n","1719/1719 [==============================] - 25s 14ms/step - loss: 0.1644 - accuracy: 0.9417 - val_loss: 0.2792 - val_accuracy: 0.9018\n","Epoch 50/50\n","1719/1719 [==============================] - 25s 15ms/step - loss: 0.1614 - accuracy: 0.9434 - val_loss: 0.2853 - val_accuracy: 0.8974\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nLPfqhOuXpQE"},"execution_count":null,"outputs":[]}]}